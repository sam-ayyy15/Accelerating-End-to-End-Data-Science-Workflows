{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b53a7b12-538d-4459-b82a-a35c8c417849",
   "metadata": {},
   "source": [
    "<img src=\"images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae497b71-bc43-471e-8970-88a1878e7cf9",
   "metadata": {},
   "source": [
    "# Accelerating End-to-End Data Science Workflows # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a149b6d1-1880-4a5d-9d71-f963d3097aa4",
   "metadata": {},
   "source": [
    "## 05 - Grouping ##\n",
    "\n",
    "**Table of Contents**\n",
    "<br>\n",
    "This notebook discusses and demonstrates how grouping in used in data science. This notebook covers the below sections: \n",
    "1. [Grouping](#Grouping)\n",
    "    * [Split, Apply, and Combine](#Split,-Apply,-and-Combine)\n",
    "    * [Exercise #1 - Average Age Per County](#Exercise-#1---Average-Age-Per-County)\n",
    "2. [Binning](#Binning)\n",
    "    * [Exercise #2 - Using the Profiler](#Exercise-#2---Using-the-Profiler)\n",
    "3. [Advanced Groupby Operations](#Advanced-Groupby-Operations)\n",
    "    * [`.apply()`](#.apply())\n",
    "    * [`.transform()`](#.transform())\n",
    "4. [Pivot Table](#Pivot-Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f2e800-7d61-4370-8a96-ebef3a6d0c0a",
   "metadata": {},
   "source": [
    "## Grouping ##\n",
    "In data science, we often would like to split data into groups and perform further analysis on them such as: \n",
    "* Aggregate based on the grouping\n",
    "* Compare metrics across different groups\n",
    "* Understand patterns in data across different groups\n",
    "* Remove duplicates or fill missing values based on group-level information\n",
    "* Create new features based on group-level statistics\n",
    "* Integrate with visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d943bf-aaad-42c8-9b2c-70c8b6c0bf44",
   "metadata": {},
   "source": [
    "Below we load in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c435b1-35d5-4971-ade1-549ae77d22db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "%load_ext cudf.pandas\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc82f3c-f1cb-436b-becb-a97635ec5f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "dtype_dict={\n",
    "    'age': 'int8', \n",
    "    'sex': 'category', \n",
    "    'county': 'category', \n",
    "    'lat': 'float32', \n",
    "    'long': 'float32', \n",
    "    'name': 'category'\n",
    "}\n",
    "        \n",
    "df=pd.read_csv('./data/uk_pop.csv', dtype=dtype_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bbdeac-9134-443b-9b38-7a980b19decf",
   "metadata": {},
   "source": [
    "## Split, Apply, and Combine ##\n",
    "We use the `.groupby()` method to to group large amounts of data and compute operations on these groups. A groupby operation involves some combination of splitting the object, applying a function, and combining the results. cuDF implements record grouping in a manner comparable to Pandas, but with some notable differences. \n",
    "\n",
    "<p><img src='images/groupby.png' width=720></p>\n",
    "\n",
    "cuDF supports a number of common `DataFrameGroupBy` computations and descriptive statistics, such as `.size()`, `.mean()`, `.count()`, `.cov()`, `.cumprod()`, `.cumsum()`, `.max()`, `.min()`, `.nunique()`. \n",
    "\n",
    "**Note**: More information about how `.groupby()` behaves for pandas and how it differs from cuDF can be found in the links below: \n",
    "* [pandas](https://pandas.pydata.org/docs/user_guide/groupby.html)\n",
    "* [cuDF](https://docs.rapids.ai/api/cudf/stable/user_guide/groupby/)\n",
    "\n",
    "Below we find the number of people in each county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b646d3-b175-4a4e-804f-43afcb6910a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "df.groupby('county').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4775215-c6d4-49b0-ba8d-4d10a7e9f434",
   "metadata": {},
   "source": [
    "**Note**: The results is unsorted. We can sort the output using the `.sort_index()` or `.sort_values()` method. \n",
    "\n",
    "Below we count the number of people with the most and least popular names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b22bb2b-8b86-45cb-ba26-3b845be5ac00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "df.groupby('name').size().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb83bfcd-d9b2-434d-a0b3-d8d435901ece",
   "metadata": {},
   "source": [
    "Below we find the approximate centers of each county using `.groupby().mean()`. When performing groupby operations, we should **only** include columns that are being used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0efddf-7c0a-4fbc-8c88-b0fad245b05f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cudf.pandas.line_profile\n",
    "# DO NOT CHANGE THIS CELL\n",
    "\n",
    "county_center_df=df[['county', 'lat', 'long']].groupby('county')[['lat', 'long']].mean()\n",
    "display(county_center_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99556b3-b75d-4755-9b03-141d4addb023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "county_center_df.columns=['lat_county_center', 'long_county_center']\n",
    "county_center_df.to_csv('county_centroid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a498f4-b298-446c-8255-60def6d3b0ed",
   "metadata": {},
   "source": [
    "### Exercise #1 - Average Age Per County ###\n",
    "We would like to find the average age for each county. We will need to use both `.groupby()` and `.sort_values()`. Using the `.mean()` method on the data grouped by `county`, identify the 5 counties with the highest average age. \n",
    "\n",
    "**Instructions**: <br>\n",
    "* Modify the `<FIXME>` only and execute the below cell find the average age for each county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd55da-814b-4ea4-9ba5-ccc1abbf7941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['county', 'age']].groupby(<<<<FIXME>>>>)['age']\\\n",
    "                     .<<<<FIXME>>>>()\\\n",
    "                     .sort_values(ascending=False)\\\n",
    "                     .head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0e38e06-3d7d-4b99-adc7-916fa6b18b2f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "\n",
    "%%cudf.pandas.line_profile\n",
    "# DO NOT CHANGE THIS CELL\n",
    "display(\n",
    "    df[['county', 'age']].groupby('county')['age']\\\n",
    "                         .mean()\\\n",
    "                         .sort_values(ascending=False)\\\n",
    "                         .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4a3e80-c5cb-410f-a5ba-fde705594c66",
   "metadata": {},
   "source": [
    "Click ... for solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fc5851-33dc-42a2-b086-6b5d7d2d65bb",
   "metadata": {},
   "source": [
    "## Binning ##\n",
    "When grouping continuous numerical data, it is sometimes helpful to bin numbers into discrete intervals or buckets. There are primarily two ways of binning: \n",
    "* Equal-width binning: divide the range into equal-sized intervals\n",
    "* Custom binning: define custom bins based on domain knowledge or specific criteria\n",
    "\n",
    "The `.cut()` function can be used to bin values into discrete intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5274991e-521f-44f7-bda7-427e7ecee8c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cudf.pandas.line_profile\n",
    "# DO NOT CHANGE THIS CELL\n",
    "\n",
    "bins=[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "df['age_bucket']=pd.cut(df['age'].values, bins=bins, right=True, include_lowest=True, labels=False)\n",
    "display(df.groupby('age_bucket').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8ec7e5-f6f4-4041-8187-578a15c73808",
   "metadata": {},
   "source": [
    "### Exercise #2 - Using the Profiler ###\n",
    "cuDF pandas will attempt to use the GPU whenever possible and fall back to CPU for certain operations. Running the code with the `cudf.pandas.line_profile` magic command generates a report showing which operations used the GPU and which used the CPU. \n",
    "\n",
    "**Instructions**: <br>\n",
    "* Notice that the below cell is a very similar operation as before, except that it uses the `range()` function for the `bins` parameter. As it stands, this is not supported in cuDF. \n",
    "* Execute the cell below to run the binning operation on the CPU.\n",
    "* Compare the time it takes to run the similar operation above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c437f-afee-408e-9144-006c4313f9f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cudf.pandas.line_profile\n",
    "# DO NOT CHANGE THIS CELL\n",
    "\n",
    "df['age_bucket']=pd.cut(df['age'].values, bins=range(0, 100, 10), right=True, include_lowest=True, labels=False)\n",
    "display(df.groupby('age_bucket').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef539b-6ab4-4f28-b84e-8b83f32d0c0c",
   "metadata": {},
   "source": [
    "**Note**: The profiler can help us identify parts of our code that could be rewritten to be more GPU-friendly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c76d718-693c-4550-8eec-3de742565a9d",
   "metadata": {},
   "source": [
    "## Advanced Groupby Operations ##\n",
    "We can also use function application helpers on `DataFrameGroupBy` instances: \n",
    "* `DataFrameGroupby.aggregate()` / `Groupby.agg()`(alias): used when we have specific computation for different columns or more than one computation on the same column\n",
    "* `DataFrameGroupby.apply()`: used when we want to perform a specific user-defined function to each group\n",
    "* `DataFrameGroupby.transform()`: used when the resulting values should be broadcast across the whole group and return a same-indexed dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059bded6-fb78-4129-b723-6fa1de7ed8f0",
   "metadata": {},
   "source": [
    "### `.apply()` ###\n",
    "The `.apply()` method will **sequentially** apply the function group-wise and concatenate the results together. We can pass a callable function to be performed on the entire DataFrame for each group. \n",
    "\n",
    "Below we calculate the distance of each person from their respective county center. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6906dc46-32fd-45f4-8be1-ff30d944d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "\n",
    "# define distance function\n",
    "def distance(lat_1, long_1, lat_2, long_2): \n",
    "    return ((lat_2-lat_1)**2+(long_2-long_1)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63906fdc-10a5-4239-951e-e9551ff8d60b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cudf.pandas.line_profile\n",
    "# DO NOT CHANGE THIS CELL\n",
    "\n",
    "distance_df=df.groupby('county')[['lat', 'long']].apply(lambda x: distance(x['lat'], x['long'], x['lat'].mean(), x['long'].mean()))\n",
    "df['R_1']=distance_df.reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447dcea4-3fc7-4501-9f67-17801f914875",
   "metadata": {},
   "source": [
    "We can also define the function in-line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a963d9-e61c-4af6-bd32-89a5b892b09b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cudf.pandas.line_profile\n",
    "# DO NOT CHANGE THIS CELL\n",
    "\n",
    "df['R_2']=df.groupby('county')[['lat', 'long']].apply(lambda x: ((x['lat'].mean()-x['lat'])**2+(x['long'].mean()-x['long'])**2)**0.5).reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15cfd17-9b05-4de4-9c9a-fa9167f2d05f",
   "metadata": {},
   "source": [
    "**Note**: This is quite slow due to the iterative nature of the `.apply()` method. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7dc9d6-8c1d-4e1f-a6c3-85d036c62c26",
   "metadata": {},
   "source": [
    "### `.transform()` ###\n",
    "The `.transform()` method aggregates each group, and broadcasts the result to the group size, resuliting in a DataFrame that is the same size and index as the input DataFrame. Underneath the hood, the `.transform()` method passes each column individually as a Series to the function. \n",
    "\n",
    "Below we group the DataFrame by `county` and transform the columns `lat` and `long` using `mean`. We will subtract the transformed mean from the original columns, then apply the distance formula to calculate the resulting distance.  By keeping the DataFrame the same shape, we can perform cuDF operations quickly, resulting in performance gain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a3b520-1da5-4486-b024-ff9c4d3e1df3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# make data types more precise\n",
    "df[['lat', 'long']]=df[['lat', 'long']].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa82c0-e7df-4f6a-837a-a9bdd3657787",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cudf.pandas.line_profile\n",
    "# DO NOT CHANGE THIS CELL\n",
    "\n",
    "c=['lat', 'long']\n",
    "df['R_3']=((df[c] - df.groupby('county')[c].transform('mean')) ** 2).sum(axis=1) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b322745-245f-4d04-83cc-dd5089debf74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858b309c-4533-4798-a22c-fe6858257cbc",
   "metadata": {},
   "source": [
    "Although the `.apply()` method is more flexible and can handle complex operations, it is generally slower. On the other hand, the `.transform()` method can be much faster. When we design the procedures to use vector operations, we will realize significant performance benefits. \n",
    "\n",
    "**Note**: `Groupby.apply()` doesn't scale well with the number of groups, therefore this performance difference will be more pronounced with higher number of groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc715eb-e357-4a92-8778-a144007a9697",
   "metadata": {},
   "source": [
    "## Pivot Table ##\n",
    "Pivot tables allow us to summarize and aggregate large datasets into a more manageable format for analysis. When using `DataFrame.pivot_table()`, we provide the `index`, `columns`, and `values` arguments, as well as `aggfunc`. This will group the data based on `index` and `columns`, and perform the aggregation on `values`. We can apply multiple aggregation functions, which is generally faster and more memory-efficient than manual grouping and aggregation for large datasets. \n",
    "\n",
    "Below we create a pivot table that counts the number of each sex in each county. Furthermore, we derive the percentage of the total for each county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8cd25-9892-458e-a9a0-8af10647f9c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cudf.pandas.line_profile\n",
    "# DO NOT CHANGE THIS CELL\n",
    "\n",
    "pvt_tbl=df[['county', 'sex', 'name']].pivot_table(index=['county'], columns=['sex'], values='name', aggfunc='count')\n",
    "pvt_tbl=pvt_tbl.apply(lambda x: x/sum(x), axis=1)\n",
    "display(pvt_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba52ec8-18bd-4f30-a3dd-ccbdface4bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e99bf3f-be76-4ebf-aed3-624d4e8695ac",
   "metadata": {},
   "source": [
    "**Well Done!** Let's move to the [next notebook](1-06_data_visualization.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e47f0a-547e-4714-878d-34eb9b75c835",
   "metadata": {},
   "source": [
    "<img src=\"images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
