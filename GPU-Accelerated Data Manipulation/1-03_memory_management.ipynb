{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def31b0f-921a-43eb-9807-8b9b31eb7b32",
   "metadata": {},
   "source": [
    "<img src=\"images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0fd4dd-f7be-4c90-8ddd-384a760ac04f",
   "metadata": {},
   "source": [
    "# Accelerating End-to-End Data Science Workflows # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8fdf2e-a481-455e-8a52-8be8472b63bf",
   "metadata": {},
   "source": [
    "## 03 - Memory Management ##\n",
    "\n",
    "**Table of Contents**\n",
    "<br>\n",
    "This notebook explores the dynamics between data and memory. This notebook covers the below sections: \n",
    "1. [Memory Management](#Memory-Management)\n",
    "    * [Memory Usage](#Memory-Usage)\n",
    "2. [Data Types](#Data-Types)\n",
    "    * [Convert Data Types](#Convert-Data-Types)\n",
    "    * [Exercise #1 - Modify `dtypes`](#Exercise-#1---Modify-dtypes)\n",
    "    * [Categorical](#Categorical)\n",
    "3. [Efficient Data Loading](#Efficient-Data-Loading)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b59367c-48bc-4c72-b1f4-4cfdfa5470cf",
   "metadata": {},
   "source": [
    "## Memory Management ##\n",
    "During the data acquisition process, data is transferred to memory in order to be operated on by the processor. Memory management is crucial for cuDF and GPU operations for several key reasons: \n",
    "* **Limited GPU memory**: GPUs typically have less memory than CPUs, therefore efficient memory management is essential to maximize the use of available GPU memory, especially for large datasets.\n",
    "* **Data transfer overhead**: Transferring data between CPU and GPU memory is relatively slow compared to GPU computation speed. Minimizing these transfers through smart memory management is critical for performance.\n",
    "* **Performance tuning**: Understanding and optimizing memory usage is key to achieving peak performance in GPU-accelerated data processing tasks.\n",
    "\n",
    "When done correctly, keeping the data on the GPU can enable cuDF and the RAPIDS ecosystem to achieve significant performance improvements, handle larger datasets, and provide more efficient data processing capabilities. \n",
    "\n",
    "Below we import the data from the csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8a623-f799-4dad-aca9-0e571bb6e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "import pandas as pd\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711d0a7f-8598-49fc-949c-5caf6029ce47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "df=pd.read_csv('./data/uk_pop.csv')\n",
    "\n",
    "# preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36416fd0-7081-42aa-bf31-d1231b81ec0b",
   "metadata": {},
   "source": [
    "### Memory Usage ###\n",
    "Memory utilization of a DataFrame depends on the date types for each column.\n",
    "\n",
    "<p><img src='images/dtypes.png' width=720></p>\n",
    "\n",
    "We can use `DataFrame.memory_usage()` to see the memory usage for each column (in bytes). Most of the common data types have a fixed size in memory, such as `int`, `float`, `datetime`, and `bool`. Memory usage for these data types is the respective memory requirement multiplied by the number of data points. For `string` data type, the memory usage reported _for pandas_ is the number of elements times 8 bytes. This accounts for the 64-bit required for the pointer that points to an address in memory but not the memory used for the actual string values. The actual memory required for a string value is 49 bytes plus an additional byte for each character. The `deep` parameter provides a more accurate memory usage report that accounts for the system-level memory consumption of the contained `string` data type. \n",
    "\n",
    "Below we get the memory usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8378207b-2d9e-4102-8408-c2dddafc8a40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# pandas memory utilization\n",
    "mem_usage_df=df.memory_usage(deep=True)\n",
    "mem_usage_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c24bb1-c4f7-440c-a949-d4c57800ec61",
   "metadata": {},
   "source": [
    "Below we define a `make_decimal()` function to convert memory size into units based on powers of 2. In contrast to units based on powers of 10, this customary convention is commonly used to report memory capacity. More information about the two definitions can be found [here](https://en.wikipedia.org/wiki/Byte#Multiple-byte_units). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae42218-1547-49fd-9123-ab508a2b03de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "suffixes = ['B', 'kB', 'MB', 'GB', 'TB', 'PB']\n",
    "def make_decimal(nbytes):\n",
    "    i=0\n",
    "    while nbytes >= 1024 and i < len(suffixes)-1:\n",
    "        nbytes/=1024.\n",
    "        i+=1\n",
    "    f=('%.2f' % nbytes).rstrip('0').rstrip('.')\n",
    "    return '%s %s' % (f, suffixes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4a613-3eea-4dce-8e71-39593ff6f226",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_decimal(mem_usage_df.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a352c0b2-65aa-4231-b753-556aca46ff49",
   "metadata": {},
   "source": [
    "Below we calculate the memory usage manually based on the data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630327b9-6dc1-4b70-9fdf-9f7763ec4d50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# get number of rows\n",
    "num_rows=len(df)\n",
    "\n",
    "# 64-bit numbers uses 8 bytes of memory\n",
    "print(f'Numerical columns use {num_rows*8} bytes of memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb22b5f4-e38f-438e-9426-61746b509e50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# check random string-typed column\n",
    "string_cols=[col for col in df.columns if df[col].dtype=='object' ]\n",
    "column_to_check=random.choice(string_cols)\n",
    "\n",
    "overhead=49\n",
    "pointer_size=8\n",
    "\n",
    "# nan==nan when value is not a number\n",
    "# nan uses 32 bytes of memory\n",
    "string_col_mem_usage_df=df[column_to_check].map(lambda x: len(x)+overhead+pointer_size if x else 32)\n",
    "string_col_mem_usage=string_col_mem_usage_df.sum()\n",
    "print(f'{column_to_check} column uses {string_col_mem_usage} bytes of memory.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e393c2-c0d0-40ee-82d2-730c4667e9b8",
   "metadata": {},
   "source": [
    "**Note**: The `string` data type is stored differently in cuDF than it is in pandas. More information about `libcudf` stores string data using the [Arrow format](https://arrow.apache.org/docs/format/Columnar.html#variable-size-binary-layout) can be found [here](https://developer.nvidia.com/blog/mastering-string-transformations-in-rapids-libcudf/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737ff50b-9426-4e08-a00a-d7ee69f48b9f",
   "metadata": {},
   "source": [
    "## Data Types ##\n",
    "By default, pandas (and cuDF) uses 64-bit for numerical values. Using 64-bit numbers provides the highest precision but many applications do not require 64-bit precision when aggregating over a very large number of data points. When possible, using 32-bit numbers reduces storage and memory requirements in half, and also typically greatly speeds up computations because only half as much data needs to be accessed in memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b77d450-c415-44b8-87ac-20ce616ec809",
   "metadata": {},
   "source": [
    "### Convert Data Types ###\n",
    "The `.astype()` method can be used to convert numerical data types to use different bit-size containers. Here we convert the `age` column from `int64` to `int8`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603f7c70-134e-4466-a790-8a18b9088ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "df['age']=df['age'].astype('int8')\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973a6dd4-2aef-44d9-8b01-8853032eddae",
   "metadata": {},
   "source": [
    "### Exercise #1 - Modify `dtypes` ###\n",
    "**Instructions**: <br>\n",
    "* Modify the `<FIXME>` only and execute the below cell to convert any 64-bit data types to their 32-bit counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7372ec76-daa6-4eda-b5fa-9aff8450f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[<<<<FIXME>>>>]=df[<<<<FIXME>>>>].astype('float32')\n",
    "df[<<<<FIXME>>>>]=df[<<<<FIXME>>>>].astype('float32')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e144e9f-f8de-4d0f-a532-8f42a72c27d4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "\n",
    "df['lat']=df['lat'].astype('float32')\n",
    "df['long']=df['long'].astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b6542d-22cc-4926-b600-a3e052c37c96",
   "metadata": {},
   "source": [
    "Click ... for solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2cd622-977c-4915-a87f-2fe03c1793f5",
   "metadata": {},
   "source": [
    "### Categorical ###\n",
    "Categorical data is a type of data that represents discrete, distinct categories or groups. They can have a meaningful order or ranking but generally cannot be used for numerical operations. When appropriate, using the `categorical` data type can reduce memory usage and lead to faster operations. It can also be used to define and maintain a custom order of categories. \n",
    "\n",
    "Below we get the number of unique values in the string columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249e4b8-5d7a-4b44-ac15-bd3360a43f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "df.select_dtypes(include='object').nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d8bd88-b39b-4043-9039-d8bd75fe851a",
   "metadata": {},
   "source": [
    "Below we convert columns with few discrete values to `category`. The `category` data type has `.categories` and `codes` properties that are accessed through `.cat`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99bebbf-2e5b-4720-96f9-9fd7d42d2fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "df['sex']=df['sex'].astype('category')\n",
    "df['county']=df['county'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b7b290-cfcf-4ff6-b6b4-454c19b44a62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "display(df['county'].cat.categories)\n",
    "print('-'*40)\n",
    "display(df['county'].cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737385ab-677c-4bef-a86a-10aa3119e29a",
   "metadata": {},
   "source": [
    "**Note**: `.astype()` can also be used to convert data to `datetime` or `object` to enable datetime and string methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552c47c2-0fbc-455e-8745-cb98fc777243",
   "metadata": {},
   "source": [
    "## Efficient Data Loading ##\n",
    "It is often advantageous to specify the most appropriate data types for each columns, based on range, precision requirement, and how they are used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b9f0c3-8598-4a28-9481-ce28fea7544b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "start=time.time()\n",
    "df=pd.read_csv('./data/uk_pop.csv')\n",
    "duration=time.time()-start\n",
    "\n",
    "mem_usage_df=df.memory_usage(deep=True)\n",
    "display(mem_usage_df)\n",
    "\n",
    "print(f'Loading {make_decimal(mem_usage_df.sum())} took {round(duration, 2)} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5729520e-3ed8-4ec6-ae1f-ba46d642f48d",
   "metadata": {},
   "source": [
    "Below we enable `cuda.pandas` to see the difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aa0f32-4d2a-43a7-bec1-f1b88bcc37c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "%load_ext cudf.pandas\n",
    "\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b724201-9ad1-4e9b-b712-f3b31bdc4104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "suffixes = ['B', 'kB', 'MB', 'GB', 'TB', 'PB']\n",
    "def make_decimal(nbytes):\n",
    "    i=0\n",
    "    while nbytes >= 1024 and i < len(suffixes)-1:\n",
    "        nbytes/=1024.\n",
    "        i+=1\n",
    "    f=('%.2f' % nbytes).rstrip('0').rstrip('.')\n",
    "    return '%s %s' % (f, suffixes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bdd7b0-8563-41db-bd8e-3a7279394ede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cudf.pandas.line_profile\n",
    "# DO NOT CHANGE THIS CELL\n",
    "start=time.time()\n",
    "\n",
    "# define data types for each column\n",
    "dtype_dict={\n",
    "    'age': 'int8', \n",
    "    'sex': 'category', \n",
    "    'county': 'category', \n",
    "    'lat': 'float64', \n",
    "    'long': 'float64', \n",
    "    'name': 'category'\n",
    "}\n",
    "        \n",
    "efficient_df=pd.read_csv('./data/uk_pop.csv', dtype=dtype_dict)\n",
    "duration=time.time()-start\n",
    "\n",
    "mem_usage_df=efficient_df.memory_usage('deep')\n",
    "display(mem_usage_df)\n",
    "\n",
    "print(f'Loading {make_decimal(mem_usage_df.sum())} took {round(duration, 2)} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4607d8-6de3-4b27-96d4-a9720d268333",
   "metadata": {},
   "source": [
    "We were able to load data faster and more efficiently. \n",
    "\n",
    "**Note**: Notice that the memory utilized on the GPU is larger than the memory used by the DataFrame. This is expected because there are intermediary processes that use some memory during the data loading process, specifically related to parsing the csv file in this case. \n",
    "\n",
    "```\n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Tesla T4            Off  | 00000000:00:1B.0 Off |                    0 |\n",
    "| N/A   32C    P0    26W /  70W |   1378MiB / 15360MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   1  Tesla T4            Off  | 00000000:00:1C.0 Off |                    0 |\n",
    "| N/A   31C    P0    26W /  70W |    168MiB / 15360MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   2  Tesla T4            Off  | 00000000:00:1D.0 Off |                    0 |\n",
    "| N/A   30C    P0    26W /  70W |    168MiB / 15360MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   3  Tesla T4            Off  | 00000000:00:1E.0 Off |                    0 |\n",
    "| N/A   30C    P0    26W /  70W |    168MiB / 15360MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "                                                                               \n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "+-----------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f7ee37-4acb-46aa-bb73-4c0139d3f6b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c031d2c7-03cb-4ac7-a195-70fc25cb191d",
   "metadata": {},
   "source": [
    "When loading data this way, we may be able to fit more data. The optimal dataset size depends on various factors including the specific operations being performed, the complexity of the workload, and the available GPU memory. To maximize acceleration, datasets should ideally fit within GPU memory, with ample space left for operations that can spike memory requirements. As a general rule of thumb, cuDF recommends data sets that are less than 50% of the GPU memory capacity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6cefea-dc64-4f13-815e-081cd35651b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# 1 gigabytes = 1073741824 bytes\n",
    "mem_capacity=16*1073741824\n",
    "\n",
    "mem_per_record=mem_usage_df.sum()/len(efficient_df)\n",
    "\n",
    "print(f'We can load {int(mem_capacity/2/mem_per_record)} number of rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaaa1ac-66ec-4323-9842-2543c6d85e4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658e9847-775f-4d12-af4e-8f896df4e6fe",
   "metadata": {},
   "source": [
    "**Well Done!** Let's move to the [next notebook](1-04_interoperability.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86451cf-60e6-4733-b431-1bc0bd586bc2",
   "metadata": {},
   "source": [
    "<img src=\"images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
